from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from typing import TypedDict, List, Optional
from dotenv import load_dotenv

load_dotenv()

class State(TypedDict):
    messages: List[HumanMessage]
    doc_type: Optional[str]
    template_content: Optional[str]
    filled_data: Optional[dict]
    violation: Optional[str]
    final_doc: Optional[str]
    retry_count: int
    restart_classification: Optional[bool]
    classification_retry_count: Optional[int]
    end_process: Optional[bool]
    parse_retry_count: Optional[int]
    parse_failed: Optional[bool]
0
class DocumentClassifyAgent:
    """ì§€ëŠ¥í˜• ë¬¸ì„œ ì´ˆì•ˆ ì‘ì„± ì‹œìŠ¤í…œ"""
    
    def __init__(self, model_name: str = "gpt-4o-mini", temperature: float = 0.7):
        """
        DocumentDraftAgent ì´ˆê¸°í™”
        
        Args:
            model_name: ì‚¬ìš©í•  OpenAI ëª¨ë¸ëª…
            temperature: LLM ì˜¨ë„ ì„¤ì •
        """
        self.model_name = model_name
        self.temperature = temperature
        
        # LLM ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model=self.model_name, 
            temperature=self.temperature
        )
        
        # ë¬¸ì„œ íƒ€ì…ë³„ í…œí”Œë¦¿ ì •ì˜
        self.doc_prompts = {
            "ì˜ì—…ë°©ë¬¸ ê²°ê³¼ë³´ê³ ì„œ": {
                "input_prompt": """
ì˜ì—…ë°©ë¬¸ ê²°ê³¼ë³´ê³ ì„œ ì‘ì„±ì„ ìœ„í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:

ã€ê¸°ë³¸ ì •ë³´ã€‘
- ë°©ë¬¸ ì œëª©: 
- Client(ê³ ê°ì‚¬ëª…): 
- ë‹´ë‹¹ì: 
- ë°©ë¬¸ Site: 
- ë‹´ë‹¹ì ì†Œì†: 
- ì—°ë½ì²˜: 
- ì˜ì—…ì œê³µì: 
- ë°©ë¬¸ì: 
- ë°©ë¬¸ì ì†Œì†: 

ã€ë‚´ìš©ã€‘
- ê³ ê°ì‚¬ ê°œìš” (ì‹ ê·œ ê³ ê°ì‚¬ì¸ ê²½ìš°): 
- í”„ë¡œì íŠ¸ ê°œìš” (ìƒˆ í”„ë¡œì íŠ¸ì¸ ê²½ìš°): 
- ë°©ë¬¸ ë° í˜‘ì˜ë‚´ìš©: 
- í–¥í›„ê³„íš ë° ì¼ì •: 
- í˜‘ì¡°ì‚¬í•­ ë° ê³µìœ ì‚¬í•­: 

ìœ„ í•­ëª©ë“¤ì„ ììœ ë¡­ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                """
            },
            "ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ ì‹ ì²­ì„œ": {
                "input_prompt": """
ë‹¤ìŒ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:

ã€ì œí’ˆì„¤ëª…íšŒ ì„¸ë¶€ ë‚´ì—­ã€‘
- êµ¬ë¶„ ë‹¨ì¼/ë³µìˆ˜:
- ì¼ì‹œ:
- ì œí’ˆëª…:
- PM ì°¸ì„:
- ì¥ì†Œ:
- ì°¸ì„ì¸ì›:
- ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ëª©ì :
- ì œí’ˆì„¤ëª…íšŒ ì£¼ìš”ë‚´ìš©:

ã€ì°¸ì„ìí˜„í™©ã€‘
<ì§ì›ì¸ ê²½ìš°>
- íŒ€ëª…/ì´ë¦„ :

<ë³´ê±´ì˜ë£Œ ì „ë¬¸ê°€ì¸ ê²½ìš°>
- ì˜ë£Œê¸°ê´€ëª…/ì´ë¦„:

ìœ„ í•­ëª©ë“¤ì„ ììœ ë¡­ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                """
            },
            "ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ ê²°ê³¼ë³´ê³ ì„œ": {
                "input_prompt": """
ë‹¤ìŒ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:

ã€ì œí’ˆì„¤ëª…íšŒ ì„¸ë¶€ ë‚´ì—­ã€‘
- êµ¬ë¶„ ë‹¨ì¼/ë³µìˆ˜:
- ì¼ì‹œ:
- ì œí’ˆëª…:
- PM ì°¸ì„:
- ì¥ì†Œ:
- ì°¸ì„ì¸ì›:
- ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ëª©ì :
- ì œí’ˆì„¤ëª…íšŒ ì£¼ìš”ë‚´ìš©:

ã€ì°¸ì„ìí˜„í™©ã€‘
<ì§ì›ì¸ ê²½ìš°>
- íŒ€ëª…/ì´ë¦„ :

<ë³´ê±´ì˜ë£Œ ì „ë¬¸ê°€ì¸ ê²½ìš°>
- ì˜ë£Œê¸°ê´€ëª…/ì´ë¦„:

ã€ì˜ˆì‚°ì‚¬ìš©ë‚´ì—­ã€‘
- ê¸ˆì•¡:
- ë©”ë‰´:
- ì£¼ë¥˜:
- 1ì¸ ê¸ˆì•¡:

ìœ„ í•­ëª©ë“¤ì„ ììœ ë¡­ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                """
            }
        }
        
        # ê·¸ë˜í”„ ì´ˆê¸°í™”
        self.app = self._build_graph()
    
    
    def classify_doc_type(self, state: State) -> State:
        """LLMì„ ì‚¬ìš©í•´ì„œ ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ê³  ë¬¸ì„œ íƒ€ì…ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
        # ì¬ì‹œë„ ì¹´ìš´í„° ì´ˆê¸°í™” (ìƒˆë¡œìš´ ë¶„ë¥˜ ì‹œì‘ì‹œì—ë§Œ)
        if state.get("classification_retry_count") is None:
            state["classification_retry_count"] = 0
        
        user_message = state["messages"][-1].content
        
        classification_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ë¬¸ì„œ íƒ€ì… ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:
1. ì˜ì—…ë°©ë¬¸ ê²°ê³¼ë³´ê³ ì„œ - ê³ ê° ë°©ë¬¸, ì˜ì—… í™œë™ ê´€ë ¨
2. ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ ì‹ ì²­ì„œ - ì œí’ˆì„¤ëª…íšŒ ì§„í–‰ ê³„íš, ì‹ ì²­ ê´€ë ¨
3. ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ ê²°ê³¼ë³´ê³ ì„œ - ì œí’ˆì„¤ëª…íšŒ ì™„ë£Œ í›„ ê²°ê³¼ ë³´ê³  ê´€ë ¨

ë°˜ë“œì‹œ ìœ„ 3ê°€ì§€ ì¤‘ í•˜ë‚˜ì˜ ì •í™•í•œ ë¬¸ì„œ íƒ€ì… ì´ë¦„ë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
ì•ì— ìˆ«ìëŠ” ì œê±°í•˜ê³  ë¬¸ì„œëª…ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
            """),
            ("human", "{user_request}")
        ])
        
        try:
            response = self.llm.invoke(classification_prompt.format_messages(user_request=user_message))
            # response.contentê°€ stringì¸ì§€ í™•ì¸
            content = response.content
            if isinstance(content, str):
                doc_type = content.strip()
            else:
                doc_type = str(content).strip()
            
            # ìœ íš¨í•œ ë¬¸ì„œ íƒ€ì…ì¸ì§€ í™•ì¸
            valid_types = ["ì˜ì—…ë°©ë¬¸ ê²°ê³¼ë³´ê³ ì„œ", "ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ ì‹ ì²­ì„œ", "ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ ê²°ê³¼ë³´ê³ ì„œ"]
            if doc_type not in valid_types:
                doc_type = response
                
            state["doc_type"] = doc_type
            print(f"ğŸ“‹ LLM ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜: {doc_type}")
            
        except Exception as e:
            print(f"âš ï¸ LLM ë¶„ë¥˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
            state["doc_type"] = response
        
        return state

    def validate_doc_type(self, state: State) -> State:
        """ë¶„ë¥˜ëœ ë¬¸ì„œ íƒ€ì…ì´ ìœ íš¨í•œì§€ í™•ì¸í•˜ê³  í…œí”Œë¦¿ì„ ì¶”ê°€í•©ë‹ˆë‹¤."""
        doc_type = state.get("doc_type", "")
        valid_types = ["ì˜ì—…ë°©ë¬¸ ê²°ê³¼ë³´ê³ ì„œ", "ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ ì‹ ì²­ì„œ", "ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ ê²°ê³¼ë³´ê³ ì„œ"]
        
        if doc_type in valid_types:
            print(f"âœ… ìœ íš¨í•œ ë¬¸ì„œ íƒ€ì…: {doc_type}")
            
            # ë¶„ë¥˜ëœ ë¬¸ì„œ íƒ€ì…ì— ë§ëŠ” í…œí”Œë¦¿ì„ stateì— ì¶”ê°€
            if doc_type in self.doc_prompts:
                state["template_content"] = self.doc_prompts[doc_type]["input_prompt"]
                print(f"ğŸ“ í…œí”Œë¦¿ ì¶”ê°€ ì™„ë£Œ: {doc_type}")
            
            state["classification_retry_count"] = 0
            return state
        else:
            retry_count = (state.get("classification_retry_count") or 0) + 1
            state["classification_retry_count"] = retry_count
            
            print(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ë¬¸ì„œ íƒ€ì…: '{doc_type}'")
            print(f"ğŸ”„ ì¬ë¶„ë¥˜ ì‹œë„ {retry_count}/3")
            
            if retry_count >= 3:
                print("âš ï¸ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ì²˜ë¦¬ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                state["end_process"] = True
            else:
                # ìµœê·¼ ë©”ì‹œì§€ë¥¼ ë‹¤ì‹œ ì‚¬ìš©í•˜ê±°ë‚˜ ê°„ë‹¨í•œ fallback ë©”ì‹œì§€ë¥¼ ì¶”ê°€ (ì˜µì…˜)
                state["messages"].append(state["messages"][-1])
            
            return state



    def doc_type_validation_router(self, state: State) -> str:
        """ë¬¸ì„œ íƒ€ì… ìœ íš¨ì„± ê²€ì‚¬ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
        doc_type = state.get("doc_type", "")
        valid_types = ["ì˜ì—…ë°©ë¬¸ ê²°ê³¼ë³´ê³ ì„œ", "ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ ì‹ ì²­ì„œ", "ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ ê²°ê³¼ë³´ê³ ì„œ"]
        retry_count = state.get("classification_retry_count") or 0
        
        if state.get("end_process") or retry_count >= 3:
            return "END"
        elif doc_type in valid_types:
            return "END"  # ìœ íš¨í•œ ë¶„ë¥˜ ì™„ë£Œì‹œ ì¢…ë£Œ
        else:
            return "classify_doc_type"  # ì¬ë¶„ë¥˜ í•„ìš”


    def _build_graph(self):
        """LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
        graph = StateGraph(State)

        # ë…¸ë“œ ì¶”ê°€
        graph.add_node("classify_doc_type", self.classify_doc_type)
        graph.add_node("validate_doc_type", self.validate_doc_type)

        # íë¦„ ì—°ê²°
        graph.set_entry_point("classify_doc_type")
        
        # ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ â†’ ìœ íš¨ì„± ê²€ì‚¬
        graph.add_edge("classify_doc_type", "validate_doc_type")
        
        # ìœ íš¨ì„± ê²€ì‚¬ ê²°ê³¼ì— ë”°ë¥¸ ë¶„ê¸°
        graph.add_conditional_edges(
            "validate_doc_type",
            self.doc_type_validation_router,
            {
                "classify_doc_type": "classify_doc_type",      # ì¬ë¶„ë¥˜ í•„ìš”
                "END": END                                     # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ì‹œ ì¢…ë£Œ
            }
        )

        return graph.compile()
    
    def run(self, user_input: str):
        """ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        initial_state = {
            "messages": [HumanMessage(content=user_input)],
            "doc_type": None,
            "template_content": None,
            "filled_data": None,
            "violation": None,
            "final_doc": None,
            "retry_count": 0,
            "restart_classification": None,
            "classification_retry_count": None
        }
        
        # ê·¸ë˜í”„ ì‹¤í–‰
        final_state = self.app.invoke(initial_state)
        
        # ë¶„ë¥˜ ê²°ê³¼ í™•ì¸
        doc_type = final_state.get("doc_type")
        valid_types = ["ì˜ì—…ë°©ë¬¸ ê²°ê³¼ë³´ê³ ì„œ", "ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ ì‹ ì²­ì„œ", "ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ ê²°ê³¼ë³´ê³ ì„œ"]
        
        if doc_type in valid_types:
            print(f"\nğŸ“‹ ë¬¸ì„œ ë¶„ë¥˜ ì™„ë£Œ: {doc_type}")
            return final_state  # State ê°ì²´ ë°˜í™˜
        else:
            print(f"\nâŒ ë¬¸ì„œ ë¶„ë¥˜ ì‹¤íŒ¨: {doc_type}")
            return None

if __name__ == "__main__":
    # ì—ì´ì „íŠ¸ ì‹¤í–‰ ì˜ˆì‹œ
    agent = DocumentClassifyAgent()
    
    print("ğŸš€ ë¬¸ì„œ ì´ˆì•ˆ ì‘ì„± ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ë¬¸ì„œ ì‘ì„± ìš”ì²­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”:")
    
    user_input = input("\n>>> ")
    
    # ì—ì´ì „íŠ¸ ì‹¤í–‰
    result = agent.run(user_input)
    
    if result:
        print("\nâœ… ì²˜ë¦¬ ì™„ë£Œ!")
        print("ë°˜í™˜ëœ ê²°ê³¼:", result)
    else:
        print("\nâŒ ì²˜ë¦¬ ì‹¤íŒ¨")