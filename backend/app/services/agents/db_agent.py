"""
ChromaDB Agent
ì„ë² ë”© ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ ë° ì§ˆë¬¸ë‹µë³€ì„ ë‹´ë‹¹í•˜ëŠ” Agent
KURE-V1 ì„ë² ë”© ëª¨ë¸ê³¼ BGE-reranker ì‚¬ìš©
"""

import logging
from typing import Dict, List, Any, Optional
from ..embedding_service import EmbeddingService
from openai import OpenAI
from ...core.config import settings

logger = logging.getLogger(__name__)

class ChromaDBAgent:
    """ChromaDB ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ Agent"""
    
    def __init__(self):
        self.embedding_service = EmbeddingService()
        self.openai_client = None
        try:
            self.openai_client = OpenAI(api_key=settings.openai_api_key)
        except Exception as e:
            logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        
        logger.info("ChromaDB Agent ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def process(self, function_args: Dict[str, Any], original_message: str) -> Dict[str, Any]:
        """
        ë¬¸ì„œ ê²€ìƒ‰ ë° ì§ˆë¬¸ë‹µë³€ ì²˜ë¦¬
        
        Args:
            function_args: OpenAI function callingì—ì„œ ì „ë‹¬ëœ ì¸ì
            original_message: ì›ë³¸ ì‚¬ìš©ì ë©”ì‹œì§€
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            query = function_args.get("query", original_message)
            document_type = function_args.get("document_type", "general")
            
            logger.info(f"ChromaDB ê²€ìƒ‰ ì‹œì‘: {query}, íƒ€ì…: {document_type}")
            
            # 1. ì„ë² ë”© ê²€ìƒ‰ ìˆ˜í–‰
            search_results = await self._search_documents(query, document_type)
            
            # 2. ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ OpenAIë¡œ ë‹µë³€ ìƒì„±
            if search_results:
                response = await self._generate_answer(query, search_results, original_message)
                
                return {
                    "response": response,
                    "sources": search_results,
                    "metadata": {
                        "agent": "chroma_db_agent",
                        "document_type": document_type,
                        "documents_found": len(search_results),
                        "search_query": query
                    }
                }
            else:
                return {
                    "response": f"'{query}'ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ì‹œë„í•´ë³´ì‹œê±°ë‚˜ ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.",
                    "sources": [],
                    "metadata": {
                        "agent": "chroma_db_agent",
                        "document_type": document_type,
                        "documents_found": 0,
                        "search_query": query
                    }
                }
                
        except Exception as e:
            logger.error(f"ChromaDB Agent ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return {
                "response": f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "sources": [],
                "metadata": {
                    "agent": "chroma_db_agent",
                    "error": str(e)
                }
            }
    
    async def _search_documents(self, query: str, document_type: str = "general") -> List[Dict[str, Any]]:
        """
        ChromaDBì—ì„œ ë¬¸ì„œ ê²€ìƒ‰
        """
        try:
            # ì„ë² ë”© ì„œë¹„ìŠ¤ë¥¼ í†µí•œ ìœ ì‚¬ë„ ê²€ìƒ‰
            if hasattr(self.embedding_service, 'search_similar_documents'):
                results = await self.embedding_service.search_similar_documents(
                    query=query,
                    limit=5
                )
                
                # ë¬¸ì„œ íƒ€ì… í•„í„°ë§ (í•„ìš”ì‹œ)
                if document_type != "general":
                    filtered_results = []
                    for result in results:
                        doc_content = result.get("document", "").lower()
                        if self._matches_document_type(doc_content, document_type):
                            filtered_results.append(result)
                    return filtered_results[:3]  # ìƒìœ„ 3ê°œë§Œ ë°˜í™˜
                
                return results[:3]  # ìƒìœ„ 3ê°œë§Œ ë°˜í™˜
            else:
                logger.warning("ì„ë² ë”© ì„œë¹„ìŠ¤ì— search_similar_documents ë©”ì†Œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                return []
                
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _matches_document_type(self, content: str, document_type: str) -> bool:
        """
        ë¬¸ì„œ ë‚´ìš©ì´ ì§€ì •ëœ íƒ€ì…ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
        """
        type_keywords = {
            "policy": ["ì •ì±…", "ë°©ì¹¨", "policy", "ê·œì¹™"],
            "manual": ["ë§¤ë‰´ì–¼", "ì•ˆë‚´ì„œ", "manual", "ê°€ì´ë“œ", "ì‚¬ìš©ë²•"],
            "regulation": ["ê·œì •", "ê·œì¹™", "regulation", "ë²•ê·œ", "ì¤€ìˆ˜ì‚¬í•­"],
            "general": []  # ëª¨ë“  ë¬¸ì„œ
        }
        
        keywords = type_keywords.get(document_type, [])
        if not keywords:  # general íƒ€ì…
            return True
            
        return any(keyword in content for keyword in keywords)
    
    async def _generate_answer(self, query: str, search_results: List[Dict[str, Any]], original_message: str) -> str:
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ OpenAIë¡œ ë‹µë³€ ìƒì„±
        """
        if not self.openai_client:
            return "OpenAI ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ ê²€ìƒ‰ ê²°ê³¼ë§Œ ì œê³µí•©ë‹ˆë‹¤:\n\n" + self._format_search_results(search_results)
        
        try:
            # ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© ì¡°í•©
            context_documents = []
            for i, result in enumerate(search_results, 1):
                doc_content = result.get("document", "ë‚´ìš© ì—†ìŒ")
                doc_source = result.get("source", f"ë¬¸ì„œ {i}")
                context_documents.append(f"[ë¬¸ì„œ {i}: {doc_source}]\n{doc_content}")
            
            context_text = "\n\n".join(context_documents)
            
            # OpenAI í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = f"""ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë“¤ì…ë‹ˆë‹¤:

{context_text}

ì‚¬ìš©ì ì§ˆë¬¸: {original_message}

ìœ„ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë‹µë³€ ì¡°ê±´:
1. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. ì œê³µëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
3. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
4. êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”
5. í•„ìš”ì‹œ ì–´ë–¤ ë¬¸ì„œì—ì„œ ê°€ì ¸ì˜¨ ì •ë³´ì¸ì§€ ì–¸ê¸‰í•˜ì„¸ìš”"""

            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼:\n\n{self._format_search_results(search_results)}"
    
    def _format_search_results(self, search_results: List[Dict[str, Any]]) -> str:
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…
        """
        if not search_results:
            return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        formatted_results = []
        for i, result in enumerate(search_results, 1):
            doc_content = result.get("document", "ë‚´ìš© ì—†ìŒ")
            doc_source = result.get("source", f"ë¬¸ì„œ {i}")
            score = result.get("score", 0.0)
            
            formatted_results.append(f"ğŸ“„ {doc_source} (ìœ ì‚¬ë„: {score:.2f})\n{doc_content[:200]}...")
        
        return "\n\n".join(formatted_results) 